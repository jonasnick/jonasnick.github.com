<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: R | nickler's]]></title>
  <link href="https://jonasnick.github.io/blog/categories/r/atom.xml" rel="self"/>
  <link href="https://jonasnick.github.io/"/>
  <updated>2020-01-26T14:48:20+00:00</updated>
  <id>https://jonasnick.github.io/</id>
  <author>
    <name><![CDATA[Jonas Nick]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reading Noun-Noun Compounds]]></title>
    <link href="https://jonasnick.github.io/blog/2013/10/14/reading-noun-noun-compounds/"/>
    <updated>2013-10-14T23:35:00+00:00</updated>
    <id>https://jonasnick.github.io/blog/2013/10/14/reading-noun-noun-compounds</id>
    <content type="html"><![CDATA[<h3>Early Influences of Compound Frequency and Semantic Transparency</h3>

<p>My bachelor thesis in Cognitive Science.
Unfortunately, I am currently not allowed to release the data nor the analysis scripts,
because the dataset is still under active research.</p>

<p><em>Abstract</em>:
This thesis evaluates psycholinguistic theories about the cognitive processing of
words. Consequently, the time-course of compound reading is analyzed using
generalized additive models in a dataset of eye movements. The theories to be
contrasted are sublexical (Taft and Forster, 1975), supralexical (Giraudo and
Grainger, 2001) vs. dual route processing (Schreuder and Baayen, 1995) and
form-then-meaning (e.g. Rastle and Davis, 2008) vs. form-and-meaning (e.g.
Feldman et al., 2009) processing.</p>

<p>As the goal is to find the best model given various predictors, some general
mechanisms of eye movements will be demonstrated, e.g. the position
in the line has substantial effects, single fixations last longer, are on shorter
words, more in the center of the word and influenced differently by frequency
measures.</p>

<p>Inspired by Kuperman et al. (2009) it is shown that already the early eye
fixations on words are guided by first constituent and compound frequency,
providing evidence for parallel dual route models.</p>

<p>Similar to Baayen et al. (2013), Latent Semantic Analysis (LSA) similarity
scores (Landauer and Dumais, 1997) permit investigating the time point of
semantic processing. The effect of LSA similarity not only shows up in the
earliest word fixations, but the data reveals that semantics plays a role even
before a word is fixated. In particular, the fixation position in the word is
more to the right, when the semantic transparency, i.e. the similarity between
compound and second constituent is high. This evidence of parafoveal semantic
processing challenges opposing findings obtained with the eye-contingent
boundary paradigm (Rayner et al., 1986). In the framework of naive
discriminative learning (Baayen et al., 2011), the effect of transparency on fixation
position reflects optimization of the landing position for accessing the orthographic
information that is most discriminative for the compound.</p>

<p><em>Keywords</em>:
reading, eye-movements, compounds, semantic similarity, morphological
processing, generalized additive model</p>

<p><a href="/papers/readingCompounds.pdf"><center><strong>Read PDF</strong></center></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Influence of Reputation on Gricean Maxims]]></title>
    <link href="https://jonasnick.github.io/blog/2013/10/14/influence-of-reputation-on-gricean-maxims/"/>
    <updated>2013-10-14T01:04:00+00:00</updated>
    <id>https://jonasnick.github.io/blog/2013/10/14/influence-of-reputation-on-gricean-maxims</id>
    <content type="html"><![CDATA[<p>As part of the course &ldquo;Game Theory and Pragmatics&rdquo; by <a href="http://www.sfs.uni-tuebingen.de/~jquinley/">Jason Quinley</a> at the <a href="http://www.sfs.uni-tuebingen.de/en/chairs.html">Institute of Linguistics</a>, I wanted to explore the influence of reputation on obeying the Gricean Maxims using data from the Q&amp;A website Stackoverflow.</p>

<p>Pragmatics is a subfield in linguistics, defined as &ldquo;dealing with the origins, uses, and effects of signs within the total behavior of the interpreters of signs&rdquo; (<a href="http://psycnet.apa.org/psycinfo/1946-02822-000">Morris, 1946</a>).
Pragmatics tries to explain why a simple sentence like &ldquo;It&rsquo;s raining.&rdquo; has a lot of different interpretations, for example(<a href="http://staff.science.uva.nl/~mfranke/Papers/Franke_PhD_thesis.pdf">Franke, 2009</a>):</p>

<ul>
<li>The speaker advises we should take an umbrella.</li>
<li>The speaker declares the picnic cancelled.</li>
<li>The speaker is sick of living in amsterdam.</li>
</ul>




<!-- more -->


<p>Herbert Grice introduced certain assumptions (<a href="http://books.google.ch/books?id=73zw8IG7mtcC&amp;lpg=PA270&amp;ots=b59dMg5U5W&amp;dq=grice%20logic%20and%20conversation&amp;lr&amp;pg=PA270#v=onepage&amp;q=grice%20logic%20and%20conversation&amp;f=false">Grice, 1975</a>) that people rely on when making pragmatic inferences in normal circumstances. He formulated the <em>Cooperative Principle</em>: &ldquo;Make your contribution such as its required, at the stage at which it occurs, by the accepted purpose or direction of the talk exchange in which your engaged.&rdquo;. Using this principle, he derived four <em>Maxims of Conversation</em>, presented as guidelines:</p>

<ul>
<li>Maxim of Quality: Do not say what you believe to be false. Do not say that for which you lack evidance.</li>
<li>Maxim of Quantity: Make your contribution as informative as is required for the current purpose of the exchange.</li>
<li>Maxim of Relation: Be relevant.</li>
<li>Maxim of Manner: Avoid ambiguity. Be brief and orderly.</li>
</ul>


<p>Grice showed that hearers can systematically interpret utterances and infer additional information that goes beyond the semantic meaning of the uttered sentence, based on the assumption that the speaker obeys the Maxims.</p>

<p>The data for studying the influence of reputation on the maxims stems from the question and answer website <a href="https://stackoverflow.com">Stackoverflow</a> (SO).
Users of the site pose programming related ques tions which others try to answer. They are encouraged to vote on the usefulness
of a question or an answer, thereby directly affecting others reputation score.
Because SO is collaboratively edited website, reputation directly determines the
privileges of a user, ranging from voting down and editing to voting on closing
or deleting questions and answers. Thus, reputation on SO is among other thing
a measure of how much the community trusts a user.
Stackoverflow provides <a href="http://blog.stackoverflow.com/2009/06/stack-overflow-creative-commons-data-dump/">monthly data dumps</a>.</p>

<div class="text-image">
<img src="https://jonasnick.github.io/InfluenceRepGrice/analyseDataset-reputationDensityPlain.png">
<div>Figure 1</div>
</div>


<p>In Figure 1 we see that there are a lot of users with low reputation, higher reputation
is getting more and more uncommon. The dashed line represents the mean.
This can be explained in part by the fact that users start out with a reputation score of one.
It looks like the distribution is following a power law, which is strengthened by Figure 2 showing that the distribution is
approximately log-normal, when users with reputation scores equal to one are excluded.</p>

<div class="text-image">
<img src="https://jonasnick.github.io/InfluenceRepGrice/analyseDataset-reputationDensityLog.png">
<div>Figure 2</div>
</div>


<p>In the following we will measure the effect of reputation by focussing on whether a question was closed or left open.
This classification task was posted on <a href="http://www.kaggle.com/c/predict-closed-questions-on-stack-overflow">kaggle</a>.</p>

<div class="text-image">
<img src="https://jonasnick.github.io/InfluenceRepGrice/analyseDataset-reputationBoxplot.png">
<div>Figure 3</div>
</div>


<p>When investigating the density of reputations given the question was closed or left open
we can see that closed questions are posed mainly by users with low reputation
(Figure 3). One interpretation is that a user with low reputation belongs
to one of two different user categories, whose members have an incentive to
choosing low effort. Those are users who have low reputation because they are
not trustful and new users who discount the future immensely because they have
a single specific question.
The inverse argument, that questions posed by users with higher reputation
have a lower probability of ending up closed is strengthened
using a logistic regression model with reputation being the only predicting variable.
This model was estimated using a dataset of 50% closed questions, whereas normally about 6% of questions end up closed.
The decision boundary is where the model estimates a 50%
probability of a closed question &ndash; it lies at a reputation of 491.
The result is that reputation is a significant influence and this model alone has an accuracy of 59.44% on test data.</p>

<p>When closing a question a moderator specifies a <a href="http://stackoverflow.com/faq#close">reason</a> for doing so, namely off topic, not constructive, not a real question, or too localized.
<strong>Interestingly, there seems to be a relation between the Gricean Maxims and the reasons for closing a question.</strong>
Questions labeled <em>off topic</em> (not related to programming) and <em>too localized</em>
(unlikely to help future visitors) clearly violate the maxim of relevance. <em>Not a
real question</em> are those that are ambiguous, vague, incomplete, overly broad, or
rhetorical, hence the maxims of manner and quantity are both violated.
The maxim of quality is violated by questions labeled <em>not constructive</em> because they are not supported by facts.
Rather, it would solicit debate, since there is no true answer.</p>

<div class="text-image">
<img src="https://jonasnick.github.io/InfluenceRepGrice/analyseDataset-reputationMaximsDensity.png">
<div>Figure 4</div>
</div>


<p>Figure 4 reveals that reputation influences which maxims are violated.
Most questions that are incomplete are posed by low reputation users, while
controversial questions are posed by high reputation users.
In other words, violations of the maxim of quality are more likely from users with high reputation,
whereas the opposite is true for the maxim of quantity and manner.
Not shown is that questions that are labeled <em>too localized</em> are in a similar reputation range like <em>not a real question</em>,
and <em>off topic</em> questions do not differ much from open questions.</p>

<p>In conclusion, even though we trust high reputation people, they are not precise about truth.
This is by no means a bad thing, as long as we take this characteristic into account when interpreting their intent.</p>

<p><strong><a href="https://github.com/jonasnick/Gricean-Classifier">Code of the analysis</a></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Regressionsmodelle und Parameterschätzverfahren]]></title>
    <link href="https://jonasnick.github.io/blog/2013/03/15/regressionsmodelle-und-parameterschatzverfahren/"/>
    <updated>2013-03-15T17:26:00+00:00</updated>
    <id>https://jonasnick.github.io/blog/2013/03/15/regressionsmodelle-und-parameterschatzverfahren</id>
    <content type="html"><![CDATA[<p><img src="https://jonasnick.github.io/images/regressionPresentation-linearFit.png" width="500"></p>

<p><a href="regression.pdf">Eine Einführung</a>, die als Ausarbeitung für das Seminar &ldquo;Maschinelles Lernen&rdquo; an der Universität Tübingen entstanden ist. Die Grundlagen linearer, nichtlinearer, logistischer und Bayes Regression werden behandelt, sowie Verfahren zur Schätzung der Modellparameter aus statistischen Annahmen vorgestellt.
Anschließend wird die logistische Regression auf den Titanic Datensatz angewandt und unter anderem gezeigt, dass das Motto &ldquo;Frauen und Kinder zuerst&rdquo; bei der Katastrophe zutraf.</p>

<p><strong>Every plot is produced using the open source statistic software <a href="http://www.r-project.org/">R</a> inside the $\LaTeX$ file (Sweave). Code is <a href="https://github.com/jonasnick/regression/blob/master/ausarbeitung/ausarbeitung.Rnw">here</a>.</strong></p>

<blockquote><p>Charakteristisch für überwachtes maschinelles Lernen, zu der auch die Regression gehört, ist das Beschreiben der Beziehung von Zielvariable und erklärender Variable aus vorliegenden Daten, also Realisierungen von Zufallsvariablen.</p>

<p>Das Regressionsmodell stellt $y$ durch die Summe einer Hypothese von $x$ und einem Fehlerterm $\epsilon$ dar.</p>

<p>$$
y = h(x) + \epsilon
$$</p></blockquote>

<p><a href="/papers/regression.pdf"><center><strong>PDF weiterlesen</strong></center></a></p>
]]></content>
  </entry>
  
</feed>
